{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "90SmJVzEY8jl"
      },
      "outputs": [],
      "source": [
        "with open('/content/ai.txt','r',encoding='utf8') as f:\n",
        "  text=f.read().lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "ciLh8KoYcKbZ",
        "outputId": "34fe1afd-6ad6-461c-fcec-87c57a8c6116"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'artificial intelligence (ai) is the simulation of human intelligence in machines that are programmed to think and act like humans. it includes the ability to learn from experience, recognize patterns, and make decisions with minimal human intervention.\\n\\nmachine learning is a core part of ai. it enables systems to automatically improve their performance by learning from data. supervised learning involves training a model on labeled data, while unsupervised learning deals with finding hidden patterns in unlabeled data. reinforcement learning teaches agents to make decisions by rewarding desired actions.\\n\\ndeep learning, a subset of machine learning, uses multi-layered neural networks to perform tasks like image recognition, speech translation, and autonomous driving. convolutional neural networks (cnns) are commonly used in computer vision, while recurrent neural networks (rnns) are effective for sequence data like text and time series.\\n\\nnatural language processing (nlp) allows computers to understand, interpret, and generate human language. nlp powers chatbots, voice assistants, translation tools, and text summarizers. transformers and attention mechanisms have revolutionized nlp, enabling models like bert and gpt to perform a wide range of language tasks.\\n\\nai is widely used in real-world applications. in healthcare, ai helps detect diseases from medical images and assists in drug discovery. in finance, it predicts market trends, detects fraud, and automates trading. in e-commerce, ai personalizes product recommendations based on user behavior.\\n\\nrobotics integrates ai to create machines that can perceive their environment and perform tasks autonomously. ai-driven robots are used in manufacturing, logistics, space exploration, and even surgery. autonomous drones, warehouse bots, and robotic arms are examples of ai in robotics.\\n\\ngenerative ai models can create realistic images, music, and even human-like text. tools like dall·e, stable diffusion, and chatgpt are examples of generative models trained on vast datasets. these models use neural networks to generate creative outputs from simple prompts.\\n\\nas ai becomes more powerful, ethical concerns grow. issues like data privacy, algorithmic bias, job displacement, and autonomous weapons raise questions about responsible ai development. fairness, accountability, transparency, and safety are essential principles in ai governance.\\n\\nexplainable ai (xai) aims to make machine learning models more interpretable, so users can understand how decisions are made. trust in ai depends not just on accuracy, but also on the system’s ability to justify its predictions in human terms.\\n\\nai continues to evolve rapidly. research in neurosymbolic ai, multi-modal learning, and few-shot learning is pushing the boundaries of what machines can do. quantum computing is expected to accelerate some ai algorithms, opening up new possibilities.\\n\\ndespite its promise, ai has limitations. models can make mistakes, require massive amounts of data and compute, and are sensitive to input changes. general artificial intelligence—machines with human-level reasoning—remains a long-term challenge.\\n\\nthe future of ai involves collaboration between humans and intelligent systems. instead of replacing humans, ai should augment human abilities, enabling better decision-making, creativity, and productivity. human-in-the-loop systems combine machine speed with human judgment.\\n\\nai is not one technology, but a set of tools. with proper design, regulation, and ethics, ai can be used to solve some of humanity’s greatest challenges — from climate modeling and education to personalized medicine and accessibility.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Q4nMA_ZgfOt9"
      },
      "outputs": [],
      "source": [
        "# Clean the text\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "text = clean_text(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "2EoAKRjlECUr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "sequence = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "n_steps = 5\n",
        "\n",
        "# Create input sequences\n",
        "sequences = []\n",
        "for i in range(n_steps, len(sequence)):\n",
        "    seq = sequence[i - n_steps:i + 1]\n",
        "    sequences.append(seq)\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "X = sequences[:, :-1]\n",
        "y = to_categorical(sequences[:, -1], num_classes=vocab_size)\n",
        "\n",
        "# Pad inputs (if needed)\n",
        "X = pad_sequences(X, maxlen=n_steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qanVshUrEfgz",
        "outputId": "5b11a8f5-271e-4ed8-ac46-12f01f94d2ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.0373 - loss: 5.7096\n",
            "Epoch 2/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0837 - loss: 5.6927\n",
            "Epoch 3/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0678 - loss: 5.6545\n",
            "Epoch 4/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0694 - loss: 5.4363\n",
            "Epoch 5/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0599 - loss: 5.1420\n",
            "Epoch 6/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0575 - loss: 5.1761\n",
            "Epoch 7/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0565 - loss: 5.1068\n",
            "Epoch 8/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0804 - loss: 5.0354\n",
            "Epoch 9/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0714 - loss: 4.9958\n",
            "Epoch 10/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0894 - loss: 4.8455\n",
            "Epoch 11/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0640 - loss: 4.7790\n",
            "Epoch 12/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0900 - loss: 4.6766\n",
            "Epoch 13/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0867 - loss: 4.7405\n",
            "Epoch 14/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0850 - loss: 4.5430\n",
            "Epoch 15/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1068 - loss: 4.4439\n",
            "Epoch 16/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1103 - loss: 4.4043\n",
            "Epoch 17/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1048 - loss: 4.3782\n",
            "Epoch 18/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1200 - loss: 4.1231\n",
            "Epoch 19/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1412 - loss: 3.9773\n",
            "Epoch 20/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1858 - loss: 3.8919\n",
            "Epoch 21/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1670 - loss: 3.8162\n",
            "Epoch 22/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1346 - loss: 3.9404\n",
            "Epoch 23/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1843 - loss: 3.5480\n",
            "Epoch 24/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2074 - loss: 3.5294\n",
            "Epoch 25/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1975 - loss: 3.4709\n",
            "Epoch 26/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2611 - loss: 3.2728\n",
            "Epoch 27/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2877 - loss: 3.1288\n",
            "Epoch 28/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2909 - loss: 3.0611\n",
            "Epoch 29/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3147 - loss: 2.9593\n",
            "Epoch 30/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3469 - loss: 2.7669\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78965e512290>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=n_steps))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=30, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GYFr8RMEmNT",
        "outputId": "1a87444e-2d0a-46ff-b567-98a9face9301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 - 0s - 10ms/step - accuracy: 0.3816 - loss: 2.7269\n",
            "Epoch 2/20\n",
            "16/16 - 0s - 9ms/step - accuracy: 0.4051 - loss: 2.6144\n",
            "Epoch 3/20\n",
            "16/16 - 0s - 10ms/step - accuracy: 0.4384 - loss: 2.5078\n",
            "Epoch 4/20\n",
            "16/16 - 0s - 9ms/step - accuracy: 0.4736 - loss: 2.4052\n",
            "Epoch 5/20\n",
            "16/16 - 0s - 19ms/step - accuracy: 0.5049 - loss: 2.3144\n",
            "Epoch 6/20\n",
            "16/16 - 0s - 23ms/step - accuracy: 0.5342 - loss: 2.2172\n",
            "Epoch 7/20\n",
            "16/16 - 0s - 13ms/step - accuracy: 0.5558 - loss: 2.1158\n",
            "Epoch 8/20\n",
            "16/16 - 0s - 19ms/step - accuracy: 0.5675 - loss: 2.0270\n",
            "Epoch 9/20\n",
            "16/16 - 0s - 20ms/step - accuracy: 0.6223 - loss: 1.9466\n",
            "Epoch 10/20\n",
            "16/16 - 0s - 15ms/step - accuracy: 0.6380 - loss: 1.8623\n",
            "Epoch 11/20\n",
            "16/16 - 0s - 20ms/step - accuracy: 0.6595 - loss: 1.7975\n",
            "Epoch 12/20\n",
            "16/16 - 0s - 18ms/step - accuracy: 0.6986 - loss: 1.7163\n",
            "Epoch 13/20\n",
            "16/16 - 0s - 15ms/step - accuracy: 0.7025 - loss: 1.6357\n",
            "Epoch 14/20\n",
            "16/16 - 0s - 14ms/step - accuracy: 0.7299 - loss: 1.5602\n",
            "Epoch 15/20\n",
            "16/16 - 0s - 9ms/step - accuracy: 0.7593 - loss: 1.4842\n",
            "Epoch 16/20\n",
            "16/16 - 0s - 9ms/step - accuracy: 0.7886 - loss: 1.4178\n",
            "Epoch 17/20\n",
            "16/16 - 0s - 18ms/step - accuracy: 0.8102 - loss: 1.3505\n",
            "Epoch 18/20\n",
            "16/16 - 0s - 21ms/step - accuracy: 0.8141 - loss: 1.2854\n",
            "Epoch 19/20\n",
            "16/16 - 0s - 17ms/step - accuracy: 0.8395 - loss: 1.2280\n",
            "Epoch 20/20\n",
            "16/16 - 0s - 9ms/step - accuracy: 0.8434 - loss: 1.1698\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78965e1fae10>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "model.fit(X, y, epochs=20, verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(\"model.h5\")\n",
        "\n",
        "# with open(\"tokenizer.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(tokenizer, f)\n"
      ],
      "metadata": {
        "id": "cLwbha_dhrJk"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **top five word predicion **"
      ],
      "metadata": {
        "id": "Yaoy4oXoszSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_top_5_words(model, tokenizer, input_text, n_steps=5, blacklist=['the']):\n",
        "    input_text = clean_text(input_text)\n",
        "    encoded = tokenizer.texts_to_sequences([input_text])[0]\n",
        "    encoded = encoded[-n_steps:]\n",
        "    padded = pad_sequences([encoded], maxlen=n_steps)\n",
        "\n",
        "    pred = model.predict(padded, verbose=0)[0]\n",
        "    top_indices = pred.argsort()[::-1]\n",
        "\n",
        "    top_words = []\n",
        "    for idx in top_indices:\n",
        "        word = tokenizer.index_word.get(idx, \"\")\n",
        "        if word and word not in blacklist:\n",
        "            top_words.append(word)\n",
        "        if len(top_words) == 5:\n",
        "            break\n",
        "\n",
        "    return top_words\n"
      ],
      "metadata": {
        "id": "ygUpQrTijJk5"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"Enter a phrase (or type 'exit'): \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    suggestions = predict_top_5_words(model, tokenizer, user_input)\n",
        "\n",
        "    print(\"Top-5 next word suggestions:\")\n",
        "    for i, word in enumerate(suggestions):\n",
        "        print(f\"{i+1}. {word}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIpPTZgHrz-I",
        "outputId": "d67a5997-3a71-4232-9e84-0e13d308615b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a phrase (or type 'exit'):  the future of Ai\n",
            "Top-5 next word suggestions:\n",
            "1. collaboration\n",
            "2. be\n",
            "3. from\n",
            "4. evolve\n",
            "5. wide\n",
            "\n",
            "Enter a phrase (or type 'exit'): the future of Ai evolve\n",
            "Top-5 next word suggestions:\n",
            "1. collaboration\n",
            "2. limitations\n",
            "3. more\n",
            "4. changes\n",
            "5. wide\n",
            "\n",
            "Enter a phrase (or type 'exit'): the future of Ai evolve changes\n",
            "Top-5 next word suggestions:\n",
            "1. between\n",
            "2. set\n",
            "3. also\n",
            "4. accuracy\n",
            "5. but\n",
            "\n",
            "Enter a phrase (or type 'exit'): the future of Ai evolve changes between\n",
            "Top-5 next word suggestions:\n",
            "1. ai\n",
            "2. human\n",
            "3. in\n",
            "4. of\n",
            "5. models\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8PnwdbbKr2hk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}